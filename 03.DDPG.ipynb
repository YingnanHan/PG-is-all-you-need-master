{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install pyvirtualdisplay\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(600, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. DDPG\n",
    "\n",
    "[T. P. Lillicrap et al., \"Continuous control with deep reinforcement learning.\" arXiv preprint arXiv:1509.02971, 2015.](https://arxiv.org/pdf/1509.02971.pdf)\n",
    "\n",
    "Deep Q Network(DQN)([Mnih et al., 2013;2015](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)) algorithm is combined advances in deep learning with reinforcement learning. However, while DQN solves problems with high-dimentional observation spaces, it can only handle discrete and low-dimentional action spaces because of using greedy policy. For learning in high-dimentional and continous action spaces, the authors combine the actor-critic approach with insights from the recent success of DQN. Deep DPG(DDPG) is based on the deterministic policy gradient(DPG) algorithm ([Silver et al., 2014](http://proceedings.mlr.press/v32/silver14.pdf)). \n",
    "\n",
    "### Deterministic policy gradient\n",
    "The DPG algorithm maintains a parameterized actor function $\\mu(s|\\theta^{\\mu})$ which specifies the current policy by deterministically mapping states to a specific action. The critic $Q(s, a)$ is learned using the Bellman equation as in Q-learning. The actor is updated by following the applying the chain rule to the expected return from the start distribution $J$ with respect to the actor parameters\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla_{\\theta^{\\mu}}J &\\approx E_{s_t\\sim\\rho^\\beta} [\\nabla_{\\theta^{\\mu}} Q(s,a|\\theta^Q)|_{s=s_t, a=\\mu(s_t|\\theta^\\mu)}] \\\\\n",
    "&= E_{s_t\\sim\\rho^\\beta} [\\nabla_{a} Q(s,a|\\theta^Q)|_{s=s_t, a=\\mu(s_t)} \\nabla_{\\theta^{\\mu}} \\mu(s|\\theta^\\mu)|_{s=s_t}]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Replay buffer\n",
    "One challenge when using neural networks for reinforcement learning is that most optimization algorithms assume that **the samples are independently and identically distributed**. When the samples are generated from exploring sequentially in an environment this assumption no longer holds. The authors used a **replay buffer** to address these issues. Transitions were sampled from the environment according to the exploration policy and the tuple $(s_t, a_t, r_t, s_{t+1})$ was stored in the replay buffer. At each timestep the actor and critic are updated by sampling a minibatch uniformly from the buffer. It allows to benefit from learning across a set of **uncorrelated** transitions.\n",
    "\n",
    "### Soft update target network\n",
    "Since the network $(Q(s,a|\\theta^Q)$ being updated is also used in calculating the target value, the Q update is prone to divergence. To avoid this, the authors use **the target network** like DQN, but modified for actor-critic and using **soft target updates**. Target netwokrs is created by copying the actor and critic networks, $Q'(s,a|\\theta^{Q'})$ and $\\mu'(s|\\theta^{\\mu`})$ respectively, that are used for calculating the target values. The weights of these target networks are then updated by having them slowly track the learned networks:\n",
    "\n",
    "$$\n",
    "\\theta' \\leftarrow \\tau \\theta + (1 - \\tau)\\theta' \\ \\ \\ {with} \\ \\tau \\ll 1.\n",
    "$$\n",
    "\n",
    "It greatly improves the stability of learning.\n",
    "\n",
    "### Exploration for continuous action space\n",
    "An advantage of offpolicies algorithms such as DDPG is that we can treat the problem of exploration independently from the learning algorithm. The authors construct an exploration policy $\\mu'$ by adding noise sampled from a noise process $\\mathcal{N}$ to the actor policy\n",
    "\n",
    "$$\n",
    "\\mu'(s_t) = \\mu(s_t|\\theta^{\\mu}_t) + \\mathcal{N}\n",
    "$$\n",
    "\n",
    "$\\mathcal{N}$ can be chosen to suit the environment. The authors used **Ornstein-Uhlenbeck process** to generate temporally correlated exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 777\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "Typically, people implement replay buffers with one of the following three data structures:\n",
    "\n",
    "- collections.deque\n",
    "- list\n",
    "- numpy.ndarray\n",
    "\n",
    "**deque** is very easy to handle once you initialize its maximum length (e.g. deque(maxlen=buffer_size)). However, the indexing operation of deque gets terribly slow as it grows up because it is [internally doubly linked list](https://wiki.python.org/moin/TimeComplexity#collections.deque). On the other hands, **list** is an array, so it is relatively faster than deque when you sample batches at every step. Its amortized cost of Get item is [O(1)](https://wiki.python.org/moin/TimeComplexity#list).\n",
    "\n",
    "Last but not least, let's see **numpy.ndarray**. numpy.ndarray is even faster than list due to the fact that it is [a homogeneous array of fixed-size items](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray), so you can get the benefits of [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference), . Whereas list is an array of pointers to objects, even when all of them are of the same type.\n",
    "\n",
    "Here, we are going to implement a replay buffer using numpy.ndarray.\n",
    "\n",
    "Reference: \n",
    "- [OpenAI spinning-up](https://github.com/openai/spinningup/blob/master/spinup/algos/sac/sac.py#L10)\n",
    "- [rainbow-is-all-you-need](https://render.githubusercontent.com/view/ipynb?commit=032d11277cf2436853478a69ca5a4aba03202598&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f437572742d5061726b2f7261696e626f772d69732d616c6c2d796f752d6e6565642f303332643131323737636632343336383533343738613639636135613461626130333230323539382f30312e64716e2e6970796e62&nwo=Curt-Park%2Frainbow-is-all-you-need&path=01.dqn.ipynb&repository_id=191133946&repository_type=Repository#Replay-buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        \"\"\"Initializate.\"\"\"\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        \"\"\"Store the transition in buffer.\"\"\"\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OU Noise\n",
    "**Ornstein-Uhlenbeck** process generates temporally correlated exploration, and it effectively copes with physical control problems of inertia.\n",
    "\n",
    "$$\n",
    "dx_t = \\theta(\\mu - x_t) dt + \\sigma dW_t\n",
    "$$\n",
    "\n",
    "Reference: \n",
    "- [Udacity github](https://github.com/udacity/deep-reinforcement-learning/blob/master/ddpg-pendulum/ddpg_agent.py)\n",
    "- [Wiki](https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\n",
    "    Taken from Udacity deep-reinforcement-learning github repository:\n",
    "    https://github.com/udacity/deep-reinforcement-learning/blob/master/\n",
    "    ddpg-pendulum/ddpg_agent.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        size: int, \n",
    "        mu: float = 0.0, \n",
    "        theta: float = 0.15, \n",
    "        sigma: float = 0.2,\n",
    "    ):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.state = np.float64(0.0)\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self) -> np.ndarray:\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.array(\n",
    "            [random.random() for _ in range(len(x))]\n",
    "        )\n",
    "        self.state = x + dx\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "We are going to use two separated networks for actor and critic. The actor network has three fully connected layers and three non-linearity functions, **ReLU** for hidden layers and **tanh** for the output layer. On the other hand, the critic network has three fully connected layers, but it used two activation functions for hidden layers **ReLU**. Plus, its input sizes of critic network are sum of state sizes and action sizes. One thing to note is that we initialize the final layer's weights and biases so that they are **uniformly distributed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int,\n",
    "        init_w: float = 3e-3,\n",
    "    ):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        self.hidden1 = nn.Linear(in_dim, 128)\n",
    "        self.hidden2 = nn.Linear(128, 128)\n",
    "        self.out = nn.Linear(128, out_dim)\n",
    "        \n",
    "        self.out.weight.data.uniform_(-init_w, init_w)\n",
    "        self.out.bias.data.uniform_(-init_w, init_w)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        x = F.relu(self.hidden1(state))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        action = self.out(x).tanh()\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        init_w: float = 3e-3,\n",
    "    ):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.hidden1 = nn.Linear(in_dim, 128)\n",
    "        self.hidden2 = nn.Linear(128, 128)\n",
    "        self.out = nn.Linear(128, 1)\n",
    "        \n",
    "        self.out.weight.data.uniform_(-init_w, init_w)\n",
    "        self.out.bias.data.uniform_(-init_w, init_w)\n",
    "\n",
    "    def forward(\n",
    "        self, state: torch.Tensor, action: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        x = torch.cat((state, action), dim=-1)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        value = self.out(x)\n",
    "        \n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG Agent\n",
    "Here is a summary of DDPGAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "|---               |---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|\\_target_soft_update| soft update from the local model to the target model.|\n",
    "|\\_plot              | plot the training progresses.                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGAgent:\n",
    "    \"\"\"DDPGAgent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        actor (nn.Module): target actor model to select actions\n",
    "        actor_target (nn.Module): actor model to predict next actions\n",
    "        actor_optimizer (Optimizer): optimizer for training actor\n",
    "        critic (nn.Module): critic model to predict state values\n",
    "        critic_target (nn.Module): target critic model to predict state values\n",
    "        critic_optimizer (Optimizer): optimizer for training critic\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        gamma (float): discount factor\n",
    "        tau (float): parameter for soft target update\n",
    "        initial_random_steps (int): initial random action steps\n",
    "        noise (OUNoise): noise generator for exploration\n",
    "        device (torch.device): cpu / gpu\n",
    "        transition (list): temporory storage for the recent transition\n",
    "        total_step (int): total step numbers\n",
    "        is_test (bool): flag to show the current mode (train / test)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        ou_noise_theta: float,\n",
    "        ou_noise_sigma: float,\n",
    "        gamma: float = 0.99,\n",
    "        tau: float = 5e-3,\n",
    "        initial_random_steps: int = 1e4,\n",
    "    ):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.shape[0]\n",
    "\n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.initial_random_steps = initial_random_steps\n",
    "                \n",
    "        # noise\n",
    "        self.noise = OUNoise(\n",
    "            action_dim,\n",
    "            theta=ou_noise_theta,\n",
    "            sigma=ou_noise_sigma,\n",
    "        )\n",
    "\n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks\n",
    "        self.actor = Actor(obs_dim, action_dim).to(self.device)\n",
    "        self.actor_target = Actor(obs_dim, action_dim).to(self.device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        \n",
    "        self.critic = Critic(obs_dim + action_dim).to(self.device)\n",
    "        self.critic_target = Critic(obs_dim + action_dim).to(self.device)\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "\n",
    "        # optimizer\n",
    "        self.actor_optimizer = \n",
    "        optim.Adam(self.actor.parameters(), lr=3e-4)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=1e-3)\n",
    "        \n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # total steps count\n",
    "        self.total_step = 0\n",
    "\n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "    \n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # if initial random action should be conducted\n",
    "        if self.total_step < self.initial_random_steps and not self.is_test:\n",
    "            selected_action = self.env.action_space.sample()\n",
    "        else:\n",
    "            selected_action = self.actor(\n",
    "                torch.FloatTensor(state).to(self.device)\n",
    "            ).detach().cpu().numpy()\n",
    "        \n",
    "        # add noise for exploration during training\n",
    "        if not self.is_test:\n",
    "            noise = self.noise.sample()\n",
    "            selected_action = np.clip(selected_action + noise, -1.0, 1.0)\n",
    "        \n",
    "        self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "    \n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "    \n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        \n",
    "        samples = self.memory.sample_batch()\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.FloatTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        masks = 1 - done\n",
    "        next_action = self.actor_target(next_state)\n",
    "        next_value = self.critic_target(next_state, next_action)\n",
    "        curr_return = reward + self.gamma * next_value * masks\n",
    "        \n",
    "        # train critic\n",
    "        values = self.critic(state, action)\n",
    "        critic_loss = F.mse_loss(values, curr_return)\n",
    "        \n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "                \n",
    "        # train actor\n",
    "        actor_loss = -self.critic(state, self.actor(state)).mean()\n",
    "        \n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        # target update\n",
    "        self._target_soft_update()\n",
    "        \n",
    "        return actor_loss.data, critic_loss.data\n",
    "    \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        actor_losses = []\n",
    "        critic_losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "        \n",
    "        for self.total_step in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "            # if episode ends\n",
    "            if done:         \n",
    "                state = env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if (\n",
    "                len(self.memory) >= self.batch_size \n",
    "                and self.total_step > self.initial_random_steps\n",
    "            ):\n",
    "                actor_loss, critic_loss = self.update_model()\n",
    "                ################################\n",
    "                actor_loss = actor_loss.to(\"cpu\")\n",
    "                critic_loss = critic_loss.to(\"cpu\")\n",
    "                ################################\n",
    "                actor_losses.append(actor_loss)\n",
    "                critic_losses.append(critic_loss)\n",
    "            \n",
    "            # plotting\n",
    "            if self.total_step % plotting_interval == 0:\n",
    "                self._plot(\n",
    "                    self.total_step, \n",
    "                    scores, \n",
    "                    actor_losses, \n",
    "                    critic_losses,\n",
    "                )\n",
    "                \n",
    "        self.env.close()\n",
    "        \n",
    "    def test(self):\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        frames = []\n",
    "        while not done:\n",
    "            frames.append(self.env.render(mode=\"rgb_array\"))\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "        \n",
    "        return frames\n",
    "    \n",
    "    def _target_soft_update(self):\n",
    "        \"\"\"Soft-update: target = tau*local + (1-tau)*target.\"\"\"\n",
    "        tau = self.tau\n",
    "        \n",
    "        for t_param, l_param in zip(\n",
    "            self.actor_target.parameters(), self.actor.parameters()\n",
    "        ):\n",
    "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
    "            \n",
    "        for t_param, l_param in zip(\n",
    "            self.critic_target.parameters(), self.critic.parameters()\n",
    "        ):\n",
    "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
    "    \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        actor_losses: List[float], \n",
    "        critic_losses: List[float], \n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        def subplot(loc: int, title: str, values: List[float]):\n",
    "            plt.subplot(loc)\n",
    "            plt.title(title)\n",
    "            plt.plot(values)\n",
    "\n",
    "        subplot_params = [\n",
    "            (131, f\"frame {frame_idx}. score: {np.mean(scores[-10:])}\", scores),\n",
    "            (132, \"actor_loss\", actor_losses),\n",
    "            (133, \"critic_loss\", critic_losses),\n",
    "        ]\n",
    "        \n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(30, 5))\n",
    "        for loc, title, values in subplot_params:\n",
    "            subplot(loc, title, values)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "*ActionNormalizer* is an action wrapper class to normalize the action values ranged in (-1. 1). Thanks to this class, we can make the agent simply select action values within the zero centered range (-1, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionNormalizer(gym.ActionWrapper):\n",
    "    \"\"\"Rescale and relocate the actions.\"\"\"\n",
    "\n",
    "    def action(self, action: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Change the range (-1, 1) to (low, high).\"\"\"\n",
    "        low = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "\n",
    "        scale_factor = (high - low) / 2\n",
    "        reloc_factor = high - scale_factor\n",
    "\n",
    "        action = action * scale_factor + reloc_factor\n",
    "        action = np.clip(action, low, high)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def reverse_action(self, action: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Change the range (low, high) to (-1, 1).\"\"\"\n",
    "        low = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "\n",
    "        scale_factor = (high - low) / 2\n",
    "        reloc_factor = high - scale_factor\n",
    "\n",
    "        action = (action - reloc_factor) / scale_factor\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see [the code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/pendulum.py) and [configurations](https://github.com/openai/gym/blob/cedecb35e3428985fd4efad738befeb75b9077f1/gym/envs/__init__.py#L81) of Pendulum-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env_id = \"Pendulum-v1\"\n",
    "env = gym.make(env_id)\n",
    "env = ActionNormalizer(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 777\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = 5000000\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "ou_noise_theta = 1.0\n",
    "ou_noise_sigma = 0.1\n",
    "initial_random_steps = 10000\n",
    "\n",
    "agent = DDPGAgent(\n",
    "    env, \n",
    "    memory_size, \n",
    "    batch_size,\n",
    "    ou_noise_theta,\n",
    "    ou_noise_sigma,\n",
    "    initial_random_steps=initial_random_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mDDPGAgent.train\u001b[1;34m(self, num_frames, plotting_interval)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# plotting\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_step \u001b[38;5;241m%\u001b[39m plotting_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mactor_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcritic_losses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mDDPGAgent._plot\u001b[1;34m(self, frame_idx, scores, actor_losses, critic_losses)\u001b[0m\n\u001b[0;32m    248\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loc, title, values \u001b[38;5;129;01min\u001b[39;00m subplot_params:\n\u001b[1;32m--> 250\u001b[0m     \u001b[43msubplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mDDPGAgent._plot.<locals>.subplot\u001b[1;34m(loc, title, values)\u001b[0m\n\u001b[0;32m    237\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(loc)\n\u001b[0;32m    238\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(title)\n\u001b[1;32m--> 239\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_base.py:490\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 490\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mindex_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1652\u001b[0m, in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1652\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1304\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;124;03m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1306\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m         \u001b[38;5;66;03m# work around\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;66;03m# https://github.com/pandas-dev/pandas/issues/27775 which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[38;5;66;03m# This code should correctly identify and coerce to a\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;66;03m# numpy array all pandas versions.\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:678\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    res = agent.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
